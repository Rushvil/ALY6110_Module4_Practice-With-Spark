# -*- coding: utf-8 -*-
"""ALY6110_Module4_Rushvil Patel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TzM2whUfjTwgxuRgB-hYMPgj90gWBhKb
"""

# innstall java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# install spark (change the version number if needed)
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz

# unzip the spark file to the current folder
!tar xf spark-3.0.0-bin-hadoop3.2.tgz

# set your spark folder to your system path environment. 
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"

# install findspark using pip
!pip install -q findspark

import pandas as pd

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

from google.colab import files
files.upload()

df = spark.read.csv('Admission_Predict.csv',inferSchema=True, header=True)

print((df.count(), len(df.columns)))
df.columns

df.printSchema()

df.describe().show()

df = df.drop('Serial No.')
df.show()

for i in df.columns:
    print(i+':',df[df[i].isNull()].count())

for col in df.columns:
    print('Corellation to chance of admit col for {} is {}'.format(
          col, df.stat.corr('Chance of Admit ',col)))

import seaborn as sns
import matplotlib.pyplot as plt

from pyspark.sql.types import *
import pyspark.sql.functions as F
from pyspark.sql.functions import udf, col

df.show(5)

sns.histplot(df.select('CGPA').toPandas(), bins = 10)

df_income = df.groupby('University Rating').agg({'CGPA' : 'avg'})
df_pandas_income = df_income.toPandas()
sns.barplot(x = df_pandas_income['University Rating'], y = df_pandas_income['avg(CGPA)'])

#Checking normal distribution of selected fetures
#GRE Score

sns.distplot(df.select('GRE Score').toPandas(), color="green")
df.select(F.skewness('GRE Score'), F.kurtosis('GRE Score')).show()

grescore = df.groupBy("GRE Score").count().sort("GRE Score", ascending= True)
grescore.toPandas().plot.bar(x='GRE Score',figsize=(20, 6))



from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(inputCols=['GRE Score','TOEFL Score','CGPA'],
                            outputCol='features')

# display dataframe
output_data = assembler.transform(df)
output_data.show()

from pyspark.ml.regression import LinearRegression

final_data = output_data.select('features', 'Chance of Admit ')

# Print schema of final data
final_data.printSchema()

train, test = final_data.randomSplit([0.7, 0.3])

models = LinearRegression(featuresCol='features',labelCol='Chance of Admit ')
model = models.fit(train)

# Get summary of the model
summary = model.summary

# Print rmse & r2
print('\033[1m' + 'RMSE:',summary.rootMeanSquaredError)
print('R2 score:', summary.r2)
print('MAE score:', summary.meanAbsoluteError)
print('MSE score:', summary.meanSquaredError)

# Transform on the test data
predictions = model.transform(test)

# Display the predictions
predictions.show(20)

# Evaluate the model
from pyspark.ml.evaluation import RegressionEvaluator

evaluator = RegressionEvaluator(predictionCol='prediction',
                                labelCol='Chance of Admit ',
                                metricName='r2')

print('\033[1m' + 'R2 on the test data:',evaluator.evaluate(predictions))

models = LinearRegression(featuresCol='features',labelCol='Chance of Admit ')
model = models.fit(test)

# Get summary of the model
summary = model.summary

# Print RMSE , R2 , MAE , MSE
print('\033[1m' + 'RMSE:',summary.rootMeanSquaredError)
print('R2 score:', summary.r2)
print('MAE score:', summary.meanAbsoluteError)
print('MSE score:', summary.meanSquaredError)

